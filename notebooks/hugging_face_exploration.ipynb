{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5795f461e1f24e9d88eece50c7f07a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b88c1d1324400b864290fc06fc4688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0347733d4069420582bf069c6dee0919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23f37a8bf44bdcb9fe994195fe6602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0d49d4d590427aa9aa74d225d4f319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT name FROM table WHERE age = 25\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"juierror/text-to-sql-with-table-schema\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"juierror/text-to-sql-with-table-schema\")\n",
    "\n",
    "def prepare_input(question: str, table: List[str]):\n",
    "    table_prefix = \"table:\"\n",
    "    question_prefix = \"question:\"\n",
    "    join_table = \",\".join(table)\n",
    "    inputs = f\"{question_prefix} {question} {table_prefix} {join_table}\"\n",
    "    input_ids = tokenizer(inputs, max_length=700, return_tensors=\"pt\").input_ids\n",
    "    return input_ids\n",
    "\n",
    "def inference(question: str, table: List[str]) -> str:\n",
    "    input_data = prepare_input(question=question, table=table)\n",
    "    input_data = input_data.to(model.device)\n",
    "    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=700)\n",
    "    result = tokenizer.decode(token_ids=outputs[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "print(inference(question=\"get people name with age equal 25\", table=[\"id\", \"name\", \"age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy.engine import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/nqb9hcfs07n91h4v5p34slp00000gn/T/ipykernel_62938/4036504853.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.replace('.', '_')\n"
     ]
    }
   ],
   "source": [
    "predicted_data_path = '/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/data/predicted-data/vehicle_data_with_clusters.csv'\n",
    "\n",
    "df = pd.read_csv(predicted_data_path)\n",
    "\n",
    "df.columns = df.columns.str.replace('.', '_')\n",
    "\n",
    "# Replace the character '/' with '_per_' all entries\n",
    "df.columns = df.columns.str.replace('/', '_per_')\n",
    "\n",
    "# drop column hybrid_in_fuel\thybrid_in_electric\taggregate_levels\tvehicle_type_cat\n",
    "df = df.drop(['hybrid_in_fuel', 'hybrid_in_electric', 'aggregate_levels','transmission_','fuel_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite://\")\n",
    "df = pd.read_csv(predicted_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicle_id', 'vehicleclass_', 'make_', 'model.1_', 'model_year',\n",
       "       'cylinders_', 'fuelconsumption_city(l/100km)',\n",
       "       'fuelconsumption_hwy(l/100km)', 'fuelconsumption_comb(l/100km)',\n",
       "       'co2emissions_(g/km)', 'number_of_gears', 'predicted_co2_rating',\n",
       "       'enginesize_(l)', 'transmission_', 'fuel_type',\n",
       "       'fuelconsumption_comb(mpg)', 'smog_rating', 'transmission_type',\n",
       "       'mapped_fuel_type', 'type_of_wheel_drive', 'vehicle_type', 'motor_(kw)',\n",
       "       'consumption_combinedle/100km', 'range1_(km)', 'recharge_time(h)',\n",
       "       'fuel_type2', 'range2_(km)', 'hybrid_fuels',\n",
       "       'consumption_city(kwh/100km)', 'fuelconsumption_hwy(kwh/100km)',\n",
       "       'fuelconsumption_comb(kwh/100km)', 'fuelconsumption_city(le/100km)',\n",
       "       'fuelconsumption_hwy(le/100km)', 'fuelconsumption_comb(le/100km)',\n",
       "       'range_(km)', 'hybrid_in_fuel', 'hybrid_in_electric',\n",
       "       'aggregate_levels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT hybrid_fuels FROM table WHERE vehicle_type = vehicle_class_ = vehicle_id AND make_ = vehicle_year AND fuelconsumption_comb(l/100km) = fuelconsumption_city(kwh/100km) = fuelconsumption_comb(kwh/100km) = fuel_type = hybrid_car\n"
     ]
    }
   ],
   "source": [
    "print(inference(question=\"Show me hybrid car models\", table=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
