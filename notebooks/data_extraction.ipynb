{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6f9879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:24.647146Z",
     "iopub.status.busy": "2023-04-20T00:25:24.646931Z",
     "iopub.status.idle": "2023-04-20T00:25:24.652274Z",
     "shell.execute_reply": "2023-04-20T00:25:24.651910Z"
    },
    "papermill": {
     "duration": 0.010685,
     "end_time": "2023-04-20T00:25:24.653546",
     "exception": false,
     "start_time": "2023-04-20T00:25:24.642861",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7a66e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:24.664648Z",
     "iopub.status.busy": "2023-04-20T00:25:24.664363Z",
     "iopub.status.idle": "2023-04-20T00:25:24.670506Z",
     "shell.execute_reply": "2023-04-20T00:25:24.669799Z"
    },
    "papermill": {
     "duration": 0.015394,
     "end_time": "2023-04-20T00:25:24.671827",
     "exception": false,
     "start_time": "2023-04-20T00:25:24.656433",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "product = {\n",
    "    \"nb\": \"/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d19d1bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:24.678180Z",
     "iopub.status.busy": "2023-04-20T00:25:24.677984Z",
     "iopub.status.idle": "2023-04-20T00:25:25.000747Z",
     "shell.execute_reply": "2023-04-20T00:25:25.000301Z"
    },
    "papermill": {
     "duration": 0.327937,
     "end_time": "2023-04-20T00:25:25.002520",
     "exception": false,
     "start_time": "2023-04-20T00:25:24.674583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6635d4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.009160Z",
     "iopub.status.busy": "2023-04-20T00:25:25.008869Z",
     "iopub.status.idle": "2023-04-20T00:25:25.011898Z",
     "shell.execute_reply": "2023-04-20T00:25:25.011344Z"
    },
    "papermill": {
     "duration": 0.008058,
     "end_time": "2023-04-20T00:25:25.013294",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.005236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf655b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.019606Z",
     "iopub.status.busy": "2023-04-20T00:25:25.019324Z",
     "iopub.status.idle": "2023-04-20T00:25:25.021640Z",
     "shell.execute_reply": "2023-04-20T00:25:25.021293Z"
    },
    "papermill": {
     "duration": 0.006887,
     "end_time": "2023-04-20T00:25:25.022865",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.015978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the current working directory to a Path object\n",
    "script_dir = Path(current_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c938ba1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.029317Z",
     "iopub.status.busy": "2023-04-20T00:25:25.029118Z",
     "iopub.status.idle": "2023-04-20T00:25:25.031860Z",
     "shell.execute_reply": "2023-04-20T00:25:25.031132Z"
    },
    "papermill": {
     "duration": 0.009191,
     "end_time": "2023-04-20T00:25:25.034801",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.025610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global model_dict\n",
    "global transmission_dict\n",
    "global fuel_dict\n",
    "global stats_can_dict \n",
    "global month_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96a34d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.041086Z",
     "iopub.status.busy": "2023-04-20T00:25:25.040829Z",
     "iopub.status.idle": "2023-04-20T00:25:25.044358Z",
     "shell.execute_reply": "2023-04-20T00:25:25.043927Z"
    },
    "papermill": {
     "duration": 0.008095,
     "end_time": "2023-04-20T00:25:25.045602",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.037507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {\"4wd/4X4\":\"Four-wheel drive\",\n",
    "\t      \"awd\": \"All-wheel drive\",\n",
    "\t      \"ffv\": \"Flexible-fuel vehicle\",\n",
    "\t      \"swb\": \"Short wheelbase\",\n",
    "\t      \"lwb\" : \"Long wheelbase\",\n",
    "\t      \"ewb\" : \"Extended wheelbase\",\n",
    "\t      \"cng\" : \"Compressed natural gas\",\n",
    "\t      \"ngv\" : \"Natural gas vehicle\",\n",
    "\t      \"#\" : \"High output engine that provides more power than the standard engine of the same size\"\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b97fb3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.051548Z",
     "iopub.status.busy": "2023-04-20T00:25:25.051343Z",
     "iopub.status.idle": "2023-04-20T00:25:25.053780Z",
     "shell.execute_reply": "2023-04-20T00:25:25.053438Z"
    },
    "papermill": {
     "duration": 0.006717,
     "end_time": "2023-04-20T00:25:25.054919",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.048202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transmission_dict = {\"A\": \"automatic\",\n",
    "\t\t     \"AM\": \"automated manual\",\n",
    "\t\t     \"AS\": \"automatic with select Shift\",\n",
    "\t\t     \"AV\": \"continuously variable\",\n",
    "\t\t     \"M\": \"manual\",\n",
    "\t\t     \"1 â€“ 10\" : \"Number of gears\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854e601c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.061683Z",
     "iopub.status.busy": "2023-04-20T00:25:25.061301Z",
     "iopub.status.idle": "2023-04-20T00:25:25.064098Z",
     "shell.execute_reply": "2023-04-20T00:25:25.063674Z"
    },
    "papermill": {
     "duration": 0.008319,
     "end_time": "2023-04-20T00:25:25.065967",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.057648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fuel_dict = {\"X\": \"regular gasoline\",\n",
    "\t     \"Z\": \"premium gasoline\",\n",
    " \t     \"D\": \"diesel\",\n",
    "\t     \"E\": \"ethanol (E85)\",\n",
    "\t     \"N\": \"natural gas\",\n",
    "\t     \"B\": \"electricity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910dd68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.072259Z",
     "iopub.status.busy": "2023-04-20T00:25:25.072044Z",
     "iopub.status.idle": "2023-04-20T00:25:25.074643Z",
     "shell.execute_reply": "2023-04-20T00:25:25.074217Z"
    },
    "papermill": {
     "duration": 0.007191,
     "end_time": "2023-04-20T00:25:25.075871",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.068680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybrid_fuel_dict = {\"B/X\": \"electricity & regular gasoline\",\n",
    "\t     'B/Z': \"electricity & premium gasoline\",\n",
    " \t     \"B/Z*\": \"electricity & premium gasoline\",\n",
    "\t     \"B/X*\": \"electricity & regular gasoline\",\n",
    "\t     \"B\": \"electricity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe18e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.082300Z",
     "iopub.status.busy": "2023-04-20T00:25:25.082089Z",
     "iopub.status.idle": "2023-04-20T00:25:25.084560Z",
     "shell.execute_reply": "2023-04-20T00:25:25.084207Z"
    },
    "papermill": {
     "duration": 0.007227,
     "end_time": "2023-04-20T00:25:25.085753",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.078526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_can_dict = {\"new_motor_vehicle_reg\": \"https://www150.statcan.gc.ca/n1/tbl/csv/20100024-eng.zip\",\n",
    "                  \"near_zero_vehicle_registrations\": \"https://www150.statcan.gc.ca/n1/tbl/csv/20100025-eng.zip\",\n",
    "                  \"fuel_sold_motor_vehicles\": \"https://www150.statcan.gc.ca/n1/tbl/csv/23100066-eng.zip\",\n",
    "                  \"vehicle_registrations_type_vehicle\": \"https://www150.statcan.gc.ca/n1/tbl/csv/23100067-eng.zip\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f0193b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.091520Z",
     "iopub.status.busy": "2023-04-20T00:25:25.091343Z",
     "iopub.status.idle": "2023-04-20T00:25:25.093821Z",
     "shell.execute_reply": "2023-04-20T00:25:25.093500Z"
    },
    "papermill": {
     "duration": 0.006605,
     "end_time": "2023-04-20T00:25:25.094971",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.088366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "month_dic = {\n",
    "            'jan': \"01\",\n",
    "            'feb': \"02\",\n",
    "            'mar': \"03\",\n",
    "            'apr': \"04\",\n",
    "            'may': \"05\",\n",
    "            'jun': \"06\",\n",
    "            'jul': \"07\",\n",
    "            'aug': \"08\",\n",
    "            'sep': \"09\",\n",
    "            'oct': \"10\",\n",
    "            'nov': \"11\",\n",
    "            'dec': \"12\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c650656c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.100845Z",
     "iopub.status.busy": "2023-04-20T00:25:25.100683Z",
     "iopub.status.idle": "2023-04-20T00:25:25.105616Z",
     "shell.execute_reply": "2023-04-20T00:25:25.105286Z"
    },
    "papermill": {
     "duration": 0.009264,
     "end_time": "2023-04-20T00:25:25.106766",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.097502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fuel_consumption_metadata_extraction() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from fuel consumption data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_result : pd.DataFrame\n",
    "        Dataframe containing metadata from fuel consumption data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract data in JSON format from URL\n",
    "        url_open_canada = \"https://open.canada.ca/data/api/action/package_show?id=98f1a129-f628-4ce4-b24d-6f16bf24dd64\"\n",
    "        json_resp = requests.get(url_open_canada)\n",
    "        # Check response is successful and application is of type JSON\n",
    "        if json_resp.status_code == 200 and 'application/json' in json_resp.headers.get('Content-Type',''):\n",
    "            # Format data and obtain entries in english\n",
    "            open_canada_data = json_resp.json()\n",
    "            data_entries = pd.json_normalize(open_canada_data['result'], record_path=\"resources\")\n",
    "            data_entries['language'] = data_entries['language'].apply(lambda col: col[0])\n",
    "            data_entries_english = data_entries[data_entries['language']=='en']\n",
    "            final_result = data_entries_english[['name','url']]\n",
    "        else:\n",
    "            print(\"Error - check the url is still valid \\\n",
    "                https://open.canada.ca/data/api/action/package_show?id=98f1a129-f628-4ce4-b24d-6f16bf24dd64\")\n",
    "            final_result = pd.DataFrame(columns=['name','url'])\n",
    "            sys.exit(1)\n",
    "        return final_result\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f8daf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.113012Z",
     "iopub.status.busy": "2023-04-20T00:25:25.112838Z",
     "iopub.status.idle": "2023-04-20T00:25:25.116095Z",
     "shell.execute_reply": "2023-04-20T00:25:25.115691Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.007725,
     "end_time": "2023-04-20T00:25:25.117226",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.109501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_raw_data(url:str):\n",
    "    \"\"\"\n",
    "    Extract raw data from a URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to extract data from\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # Perform query\n",
    "        csv_req = requests.get(url)\n",
    "        # Parse content\n",
    "        url_content = csv_req\n",
    "        \n",
    "        return url_content\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"OOps: Something Else\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90216485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.123555Z",
     "iopub.status.busy": "2023-04-20T00:25:25.123223Z",
     "iopub.status.idle": "2023-04-20T00:25:25.129003Z",
     "shell.execute_reply": "2023-04-20T00:25:25.128592Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.010369,
     "end_time": "2023-04-20T00:25:25.130210",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.119841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_raw_data(folder_path: str, url_content: str, file_name: str) -> None:\n",
    "    \"\"\"\n",
    "    This function saves the raw data obtained using extract_raw_data() into a CSV file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data will be saved\n",
    "    url_content : str\n",
    "        Content of the URL to be saved\n",
    "    file_name : str\n",
    "        Name of the file to save the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Save content into file\n",
    "    csv_file = open(Path(folder_path, file_name), 'wb')\n",
    "    csv_file.write(url_content.content)\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "def rename_fuel_data_columns(folder_path, csv_file_name)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function reads a csv and changes its column names\n",
    "    to lowecase, removes spaces and replaces them with underscores\n",
    "    and removes the pound sign from the column names\n",
    "\n",
    "    This function assumes the original csv file has two headers!!!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data is saved\n",
    "    csv_file_name : str\n",
    "        Name of the csv file to be read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        final_df : pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(Path(folder_path,csv_file_name), sep=\",\", low_memory=False, encoding='cp1252')\n",
    "\n",
    "    # Data cleaning\n",
    "    sample_df_col = df.dropna(thresh=1 ,axis=1).dropna(thresh=1 ,axis=0)\n",
    "    sample_df_col.columns = [item.lower() for item in sample_df_col.columns]\n",
    "    sample_df_no_footer = sample_df_col.dropna(thresh=3 ,axis=0)\n",
    "    \n",
    "    # Remove Unnamed cols\n",
    "    cols = sample_df_no_footer.columns\n",
    "    cleaned_cols = [re.sub(r'unnamed: \\d*', \"fuel consumption\", item) if \"unnamed\" in item else item for item in cols]\n",
    "\n",
    "\n",
    "    # Clean row 1 on df\n",
    "    str_item_cols = [str(item) for item in sample_df_no_footer.iloc[0:1,].values[0]]\n",
    "    str_non_nan = [\"\" if item=='nan' else item for item in str_item_cols]\n",
    "\n",
    "    # Form new columns\n",
    "    new_cols = []\n",
    "    for itema,itemb in zip(cleaned_cols, str_non_nan):\n",
    "        new_cols.append(f'{itema}_{itemb}'.lower().replace(\"*\",\"\").replace(\" \",\"\").replace(r'#=highoutputengine',\"\"))\n",
    "\n",
    "    # Reset column names\n",
    "    final_df = sample_df_no_footer.iloc[1:, ].copy()\n",
    "    final_df.columns = new_cols\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf69021c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.136690Z",
     "iopub.status.busy": "2023-04-20T00:25:25.136497Z",
     "iopub.status.idle": "2023-04-20T00:25:25.140974Z",
     "shell.execute_reply": "2023-04-20T00:25:25.140568Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.009045,
     "end_time": "2023-04-20T00:25:25.142174",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.133129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_clean_csv_file(folder_path, csv_file_name) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function reads a csv file and performs data cleaning\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data is saved\n",
    "    csv_file_name : str\n",
    "        Name of the csv file to be read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_df : pd.DataFrame\n",
    "        Dataframe containing the cleaned data\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    final_df = rename_fuel_data_columns(folder_path, csv_file_name)\n",
    "\n",
    "    # Additional data cleaning\n",
    "    final_df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Turn make, model.1_, vehicleclass_ into lowercase\n",
    "    final_df['make_'] = final_df['make_'].str.lower().str.strip()\n",
    "    final_df['model.1_'] = final_df['model.1_'].str.lower()\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].str.lower()\n",
    "\n",
    "    # Character cleaning for vehicleclass_: replace \":\" with \"-\"\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].str.replace(\":\",\" -\")\n",
    "\n",
    "    # Turn make, model.1_, vehicleclass_ into categorical variables\n",
    "    final_df['make_'] = final_df['make_'].astype('category')\n",
    "    final_df['model.1_'] = final_df['model.1_'].astype('category')\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].astype('category')\n",
    "\n",
    "    # Mappings\n",
    "    final_df = final_df.join(final_df['transmission_'].str.split(r'(\\d+)', \\\n",
    "        expand=True).drop(columns=[2]).rename(columns={\n",
    "                                                        0:\"transmission_type\",\n",
    "                                                        1:\"number_of_gears\"}))\n",
    "    final_df['transmission_type'] = final_df['transmission_type'].map(transmission_dict)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a240793c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.148261Z",
     "iopub.status.busy": "2023-04-20T00:25:25.148094Z",
     "iopub.status.idle": "2023-04-20T00:25:25.150608Z",
     "shell.execute_reply": "2023-04-20T00:25:25.150223Z"
    },
    "papermill": {
     "duration": 0.00685,
     "end_time": "2023-04-20T00:25:25.151823",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.144973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_model_key_words(s, dictionary):\n",
    "    \"\"\"\n",
    "    Add values from footnote\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        row of dataframe\n",
    "    dictionary : dict\n",
    "        one of the dictionaries defined globally.\n",
    "    \"\"\"\n",
    "\n",
    "    group = \"unspecified\"\n",
    "    for key in dictionary:\n",
    "        if key in s:\n",
    "            group = dictionary[key]\n",
    "            break\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc78156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.158194Z",
     "iopub.status.busy": "2023-04-20T00:25:25.157999Z",
     "iopub.status.idle": "2023-04-20T00:25:25.161548Z",
     "shell.execute_reply": "2023-04-20T00:25:25.161179Z"
    },
    "papermill": {
     "duration": 0.008095,
     "end_time": "2023-04-20T00:25:25.162726",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.154631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_stats_can_data(stats_can_url: str, folder_path:str, file_name : str) -> None:\n",
    "    \"\"\"\n",
    "    This function extracts data from StatsCan and saves it into a CSV file\n",
    "    Parameters:\n",
    "        stats_can_url (str): URL to StatsCan data\n",
    "        folder_path (str): Path to folder where data will be saved\n",
    "        file_name (str): Name of file where data will be saved\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    resp = urlopen(stats_can_url)\n",
    "    myzip = ZipFile(BytesIO(resp.read()))\n",
    "    extraction_file_name = [item for item in myzip.namelist() if \"MetaData\" not in item]\n",
    "    stats_can_csv = myzip.open(extraction_file_name[0])\n",
    "    stats_can_df = pd.read_csv(stats_can_csv)\n",
    "    stats_can_df.drop(columns=['DGUID',\n",
    "                             'UOM_ID',\n",
    "                             'SCALAR_ID',\n",
    "                             'VECTOR',\n",
    "                             'COORDINATE',\n",
    "                             'STATUS',\n",
    "                             'SYMBOL',\n",
    "                             'TERMINATED',\n",
    "                             'DECIMALS'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    stats_can_df.to_csv(Path(folder_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41342fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.168742Z",
     "iopub.status.busy": "2023-04-20T00:25:25.168543Z",
     "iopub.status.idle": "2023-04-20T00:25:25.174380Z",
     "shell.execute_reply": "2023-04-20T00:25:25.174003Z"
    },
    "papermill": {
     "duration": 0.010127,
     "end_time": "2023-04-20T00:25:25.175581",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.165454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_json_car_sales(json_filen_name, path) -> list():\n",
    "    \"\"\"\n",
    "    This function processes the JSON file containing car sales data and returns a dataframe\n",
    "    Parameters:\n",
    "        json_file_name (str): Name of JSON file\n",
    "        path (str): Path to folder where JSON file is located\n",
    "    Returns:\n",
    "        df_expanded_long (pd.DataFrame): Dataframe containing car sales data in long format\n",
    "        df_expanded_wide (pd.DataFrame): Dataframe containing car sales data in wide format\n",
    "\n",
    "    \"\"\"\n",
    "    json_df = pd.read_json(Path(path,json_filen_name)).set_index(\"model\")\n",
    "    json_df.dropna(how=\"all\", inplace=True)\n",
    "    \n",
    "    # Wide format\n",
    "    wide_df = pd.read_json(Path(path,json_filen_name))\n",
    "    df_expanded_wide = wide_df.join(wide_df.reset_index()['model'].str.split(' ', 1, expand=True).rename(columns={0:'make', 1:'model_'})).drop(columns=[\"model\"])\n",
    "    df_expanded_wide['year'] = json_filen_name.split(\"_\")[0]\n",
    "\n",
    "    # long format\n",
    "    long_format_df = pd.DataFrame(json_df.T.unstack()).reset_index().rename(columns={\"level_1\":\"month\",0:\"number_units_sold\"})\n",
    "    df_expanded_long = long_format_df.join(long_format_df.reset_index()['model'].str.split(' ', 1, expand=True).rename(columns={0:'make', 1:'model_'})).drop(columns=[\"model\"])\n",
    "    df_expanded_long['year'] = json_filen_name.split(\"_\")[0]\n",
    "    df_expanded_long['month']  = df_expanded_long['month'].map(month_dic) \n",
    "\n",
    "    # Remove ',' from number_units_sold\n",
    "    df_expanded_long['number_units_sold'] = df_expanded_long['number_units_sold'].str.replace(\",\",\"\")\n",
    "\n",
    "    # Transform month and number_units_sold to int \n",
    "    df_expanded_long['month'] = df_expanded_long['month'].astype('int')\n",
    "    df_expanded_long['number_units_sold'] = df_expanded_long['number_units_sold'].astype('int')\n",
    "\n",
    "    # Combine 'month' and 'year' into 'date' column and convert to datetime in format YYYY-MM \n",
    "    df_expanded_long['date'] = df_expanded_long['year'].astype(str) + \"-\" + df_expanded_long['month'].astype(str)\n",
    "    # Convert 'date' to datetime\n",
    "    df_expanded_long['date'] = pd.to_datetime(df_expanded_long['date'], format='%Y-%m')\n",
    "    # Drop 'month' and 'year' columns\n",
    "    df_expanded_long.drop(columns=['month','year'], inplace=True)\n",
    "\n",
    "    return df_expanded_long, df_expanded_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d205c",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.002527,
     "end_time": "2023-04-20T00:25:25.180893",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.178366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169f4a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T00:25:25.187332Z",
     "iopub.status.busy": "2023-04-20T00:25:25.187084Z",
     "iopub.status.idle": "2023-04-20T00:25:36.610614Z",
     "shell.execute_reply": "2023-04-20T00:25:36.609709Z"
    },
    "papermill": {
     "duration": 11.430385,
     "end_time": "2023-04-20T00:25:36.613777",
     "exception": false,
     "start_time": "2023-04-20T00:25:25.183392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data path:  /Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/data/raw\n",
      "Clean data path:  /Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/data/processed\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    # Variable initialization\n",
    "    raw_data_path = script_dir / 'data' / 'raw'\n",
    "    clean_data_path = script_dir / 'data' / 'processed'\n",
    "    \n",
    "    print(\"Raw data path: \", raw_data_path)\n",
    "    print(\"Clean data path: \", clean_data_path)\n",
    "    \n",
    "    # Master dataframe initialization\n",
    "    fuel_based_df = []\n",
    "\n",
    "    # Fuel consumption metadata extraction urls\n",
    "    data_entries_english = fuel_consumption_metadata_extraction()\n",
    "    \n",
    "    # Iterate over entries\n",
    "    for item in data_entries_english.iterrows():\n",
    "        name, url = item[1][\"name\"], item[1][\"url\"]\n",
    "        \n",
    "        if \"Original\" in name:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Form file name\n",
    "        file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "        # Extract raw data\n",
    "        item_based_url  = extract_raw_data(url)\n",
    "\n",
    "        # Save raw data into a csv file\n",
    "        save_raw_data(raw_data_path,item_based_url, file_name)\n",
    "        \n",
    "        # Read and clean csv file\n",
    "        final_df = read_and_clean_csv_file(raw_data_path, name.replace(\" \",\"_\")+\".csv\")\n",
    "\n",
    "        # Populate dataframe with information from the footnotes\n",
    "        if \"hybrid\" in name:\n",
    "            # Strip numbers from file_name\n",
    "            name = re.sub(r'\\d+', '', name)\n",
    "            # Strip parenthesis and - from name\n",
    "            name = name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"\")\n",
    "            # Form file name\n",
    "            file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "            final_df.rename(columns={'fuel.1_type2': 'fuel_type2',\n",
    "                          'consumption.1_city(l/100km)': 'fuelconsumption_city(l/100km)',\n",
    "                        }, inplace=True)\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type2'].map(fuel_dict)\n",
    "            final_df['hybrid_fuels'] = final_df['fuel_type1'].map(hybrid_fuel_dict)\n",
    "            \n",
    "            final_df['id'] = range(1, len(final_df) + 1)\n",
    "            final_df['vehicle_type'] = \"hybrid\"\n",
    "            final_df.to_csv(Path(clean_data_path,file_name), index=False)\n",
    "        elif \"electric\" in name and \"hybrid\" not in name: \n",
    "            # Strip numbers from file_name\n",
    "            name = re.sub(r'\\d+', '', name)\n",
    "            # Strip parenthesis and - from name\n",
    "            name = name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"\")\n",
    "            # Form file name\n",
    "            file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type'].map(fuel_dict)\n",
    "            final_df['id'] = range(1, len(final_df) + 1)\n",
    "            final_df['vehicle_type'] = \"electric\"\n",
    "            final_df.to_csv(Path(clean_data_path,file_name), index=False)\n",
    "        else:\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type'].map(fuel_dict)\n",
    "            final_df[\"type_of_wheel_drive\"] = final_df['model.1_'].apply(lambda x: convert_model_key_words(x, model_dict)) \n",
    "            fuel_based_df.append(final_df)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    fuel_based_df = pd.concat(fuel_based_df)\n",
    "\n",
    "    # add an id column where each row is a unique id (1, 2, 3, 4, ...)\n",
    "    fuel_based_df['id'] = range(1, len(fuel_based_df) + 1)\n",
    "\n",
    "    # Add a column called vehicle_type\n",
    "    fuel_based_df['vehicle_type'] = \"fuel-only\"\n",
    "    \n",
    "\n",
    "    # Save dataframes\n",
    "    fuel_based_df.to_csv(Path(clean_data_path,\"1995_today_vehicle_fuel_consumption.csv\"), index=False)\n",
    "    \n",
    "    # Extract StatsCan data\n",
    "    for keys in stats_can_dict:\n",
    "        extract_stats_can_data(stats_can_dict[keys], clean_data_path, f'{keys}.csv')\n",
    "\n",
    "    # # Extract car sales data\n",
    "    # long_format_2021_sep,df_2021 =  process_json_car_sales(\"2021_canada_vehicle_sales.json\", raw_data_path)\n",
    "    # long_format_2020_sep,df_2020 =  process_json_car_sales(\"2020_canada_vehicle_sales.json\", raw_data_path)\n",
    "    # long_format_2019_sep,df_2019 =  process_json_car_sales(\"2019_canada_vehicle_sales.json\", raw_data_path)\n",
    "\n",
    "    # # Concatenate car sales data \n",
    "    # long_format_car_sales = pd.concat([long_format_2019_sep, long_format_2020_sep, long_format_2021_sep])\n",
    "    # wide_format_car_sales = pd.concat([df_2019, df_2020, df_2021])\n",
    "\n",
    "    # # Save car sales data\n",
    "    # long_format_car_sales.to_csv(Path(clean_data_path,\"long_format_car_sales.csv\"), index=False)\n",
    "    # wide_format_car_sales.to_csv(Path(clean_data_path,\"wide_format_car_sales.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "papermill": {
   "duration": 13.45195,
   "end_time": "2023-04-20T00:25:36.943300",
   "exception": null,
   "input_path": "/var/folders/2t/nqb9hcfs07n91h4v5p34slp00000gn/T/tmpe2lhcuvq.ipynb",
   "output_path": "/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb",
   "parameters": {
    "product": {
     "nb": "/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb"
    }
   },
   "start_time": "2023-04-20T00:25:23.491350"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}