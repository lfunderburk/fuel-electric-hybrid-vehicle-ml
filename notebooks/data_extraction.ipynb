{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca03c57f",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [18]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042cc390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:08.806894Z",
     "iopub.status.busy": "2023-04-18T23:41:08.806455Z",
     "iopub.status.idle": "2023-04-18T23:41:08.813865Z",
     "shell.execute_reply": "2023-04-18T23:41:08.813358Z"
    },
    "papermill": {
     "duration": 0.01409,
     "end_time": "2023-04-18T23:41:08.815524",
     "exception": false,
     "start_time": "2023-04-18T23:41:08.801434",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# declare a list tasks whose products you want to use as inputs\n",
    "upstream = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7e7a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:08.822609Z",
     "iopub.status.busy": "2023-04-18T23:41:08.822244Z",
     "iopub.status.idle": "2023-04-18T23:41:08.824805Z",
     "shell.execute_reply": "2023-04-18T23:41:08.824404Z"
    },
    "papermill": {
     "duration": 0.007457,
     "end_time": "2023-04-18T23:41:08.826047",
     "exception": false,
     "start_time": "2023-04-18T23:41:08.818590",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "product = {\n",
    "    \"nb\": \"/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff16b6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:08.832108Z",
     "iopub.status.busy": "2023-04-18T23:41:08.831895Z",
     "iopub.status.idle": "2023-04-18T23:41:09.162651Z",
     "shell.execute_reply": "2023-04-18T23:41:09.162162Z"
    },
    "papermill": {
     "duration": 0.335844,
     "end_time": "2023-04-18T23:41:09.164378",
     "exception": false,
     "start_time": "2023-04-18T23:41:08.828534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de4d8f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.170333Z",
     "iopub.status.busy": "2023-04-18T23:41:09.170051Z",
     "iopub.status.idle": "2023-04-18T23:41:09.172523Z",
     "shell.execute_reply": "2023-04-18T23:41:09.172132Z"
    },
    "papermill": {
     "duration": 0.006914,
     "end_time": "2023-04-18T23:41:09.173794",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.166880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global model_dict\n",
    "global transmission_dict\n",
    "global fuel_dict\n",
    "global stats_can_dict \n",
    "global month_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff7f821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.180501Z",
     "iopub.status.busy": "2023-04-18T23:41:09.180236Z",
     "iopub.status.idle": "2023-04-18T23:41:09.183130Z",
     "shell.execute_reply": "2023-04-18T23:41:09.182774Z"
    },
    "papermill": {
     "duration": 0.0074,
     "end_time": "2023-04-18T23:41:09.184416",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.177016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {\"4wd/4X4\":\"Four-wheel drive\",\n",
    "\t      \"awd\": \"All-wheel drive\",\n",
    "\t      \"ffv\": \"Flexible-fuel vehicle\",\n",
    "\t      \"swb\": \"Short wheelbase\",\n",
    "\t      \"lwb\" : \"Long wheelbase\",\n",
    "\t      \"ewb\" : \"Extended wheelbase\",\n",
    "\t      \"cng\" : \"Compressed natural gas\",\n",
    "\t      \"ngv\" : \"Natural gas vehicle\",\n",
    "\t      \"#\" : \"High output engine that provides more power than the standard engine of the same size\"\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af93c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.189868Z",
     "iopub.status.busy": "2023-04-18T23:41:09.189681Z",
     "iopub.status.idle": "2023-04-18T23:41:09.191997Z",
     "shell.execute_reply": "2023-04-18T23:41:09.191657Z"
    },
    "papermill": {
     "duration": 0.006372,
     "end_time": "2023-04-18T23:41:09.193158",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.186786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transmission_dict = {\"A\": \"automatic\",\n",
    "\t\t     \"AM\": \"automated manual\",\n",
    "\t\t     \"AS\": \"automatic with select Shift\",\n",
    "\t\t     \"AV\": \"continuously variable\",\n",
    "\t\t     \"M\": \"manual\",\n",
    "\t\t     \"1 â€“ 10\" : \"Number of gears\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b21f86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.198838Z",
     "iopub.status.busy": "2023-04-18T23:41:09.198638Z",
     "iopub.status.idle": "2023-04-18T23:41:09.200958Z",
     "shell.execute_reply": "2023-04-18T23:41:09.200606Z"
    },
    "papermill": {
     "duration": 0.006705,
     "end_time": "2023-04-18T23:41:09.202265",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.195560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fuel_dict = {\"X\": \"regular gasoline\",\n",
    "\t     \"Z\": \"premium gasoline\",\n",
    " \t     \"D\": \"diesel\",\n",
    "\t     \"E\": \"ethanol (E85)\",\n",
    "\t     \"N\": \"natural gas\",\n",
    "\t     \"B\": \"electricity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda5320a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.207611Z",
     "iopub.status.busy": "2023-04-18T23:41:09.207439Z",
     "iopub.status.idle": "2023-04-18T23:41:09.210308Z",
     "shell.execute_reply": "2023-04-18T23:41:09.209941Z"
    },
    "papermill": {
     "duration": 0.006911,
     "end_time": "2023-04-18T23:41:09.211575",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.204664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hybrid_fuel_dict = {\"B/X\": \"electricity & regular gasoline\",\n",
    "\t     'B/Z': \"electricity & premium gasoline\",\n",
    " \t     \"B/Z*\": \"electricity & premium gasoline\",\n",
    "\t     \"B/X*\": \"electricity & regular gasoline\",\n",
    "\t     \"B\": \"electricity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d004c6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.216965Z",
     "iopub.status.busy": "2023-04-18T23:41:09.216812Z",
     "iopub.status.idle": "2023-04-18T23:41:09.218912Z",
     "shell.execute_reply": "2023-04-18T23:41:09.218554Z"
    },
    "papermill": {
     "duration": 0.006111,
     "end_time": "2023-04-18T23:41:09.220116",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.214005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_can_dict = {\"new_motor_vehicle_reg\": \"https://www150.statcan.gc.ca/n1/tbl/csv/20100024-eng.zip\",\n",
    "                  \"near_zero_vehicle_registrations\": \"https://www150.statcan.gc.ca/n1/tbl/csv/20100025-eng.zip\",\n",
    "                  \"fuel_sold_motor_vehicles\": \"https://www150.statcan.gc.ca/n1/tbl/csv/23100066-eng.zip\",\n",
    "                  \"vehicle_registrations_type_vehicle\": \"https://www150.statcan.gc.ca/n1/tbl/csv/23100067-eng.zip\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495a221e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.225381Z",
     "iopub.status.busy": "2023-04-18T23:41:09.225148Z",
     "iopub.status.idle": "2023-04-18T23:41:09.227717Z",
     "shell.execute_reply": "2023-04-18T23:41:09.227308Z"
    },
    "papermill": {
     "duration": 0.006572,
     "end_time": "2023-04-18T23:41:09.228979",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.222407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "month_dic = {\n",
    "            'jan': \"01\",\n",
    "            'feb': \"02\",\n",
    "            'mar': \"03\",\n",
    "            'apr': \"04\",\n",
    "            'may': \"05\",\n",
    "            'jun': \"06\",\n",
    "            'jul': \"07\",\n",
    "            'aug': \"08\",\n",
    "            'sep': \"09\",\n",
    "            'oct': \"10\",\n",
    "            'nov': \"11\",\n",
    "            'dec': \"12\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00905e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.234656Z",
     "iopub.status.busy": "2023-04-18T23:41:09.234461Z",
     "iopub.status.idle": "2023-04-18T23:41:09.239610Z",
     "shell.execute_reply": "2023-04-18T23:41:09.239246Z"
    },
    "papermill": {
     "duration": 0.009383,
     "end_time": "2023-04-18T23:41:09.240777",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.231394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fuel_consumption_metadata_extraction() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from fuel consumption data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_result : pd.DataFrame\n",
    "        Dataframe containing metadata from fuel consumption data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract data in JSON format from URL\n",
    "        url_open_canada = \"https://open.canada.ca/data/api/action/package_show?id=98f1a129-f628-4ce4-b24d-6f16bf24dd64\"\n",
    "        json_resp = requests.get(url_open_canada)\n",
    "        # Check response is successful and application is of type JSON\n",
    "        if json_resp.status_code == 200 and 'application/json' in json_resp.headers.get('Content-Type',''):\n",
    "            # Format data and obtain entries in english\n",
    "            open_canada_data = json_resp.json()\n",
    "            data_entries = pd.json_normalize(open_canada_data['result'], record_path=\"resources\")\n",
    "            data_entries['language'] = data_entries['language'].apply(lambda col: col[0])\n",
    "            data_entries_english = data_entries[data_entries['language']=='en']\n",
    "            final_result = data_entries_english[['name','url']]\n",
    "        else:\n",
    "            print(\"Error - check the url is still valid \\\n",
    "                https://open.canada.ca/data/api/action/package_show?id=98f1a129-f628-4ce4-b24d-6f16bf24dd64\")\n",
    "            final_result = pd.DataFrame(columns=['name','url'])\n",
    "            sys.exit(1)\n",
    "        return final_result\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb5ce9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.246577Z",
     "iopub.status.busy": "2023-04-18T23:41:09.246402Z",
     "iopub.status.idle": "2023-04-18T23:41:09.249391Z",
     "shell.execute_reply": "2023-04-18T23:41:09.249018Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.007321,
     "end_time": "2023-04-18T23:41:09.250580",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.243259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_raw_data(url:str):\n",
    "    \"\"\"\n",
    "    Extract raw data from a URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to extract data from\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # Perform query\n",
    "        csv_req = requests.get(url)\n",
    "        # Parse content\n",
    "        url_content = csv_req\n",
    "        \n",
    "        return url_content\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(\"Http Error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Error Connecting:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(\"Timeout Error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"OOps: Something Else\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a0efc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.256059Z",
     "iopub.status.busy": "2023-04-18T23:41:09.255899Z",
     "iopub.status.idle": "2023-04-18T23:41:09.261042Z",
     "shell.execute_reply": "2023-04-18T23:41:09.260713Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.009176,
     "end_time": "2023-04-18T23:41:09.262223",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.253047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_raw_data(folder_path: str, url_content: str) -> None:\n",
    "    \"\"\"\n",
    "    This function saves the raw data obtained using extract_raw_data() into a CSV file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data will be saved\n",
    "    url_content : str\n",
    "        Content of the URL to be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Save content into file\n",
    "    csv_file = open(Path(folder_path,file_name), 'wb')\n",
    "    csv_file.write(url_content.content)\n",
    "    csv_file.close()\n",
    "\n",
    "def rename_fuel_data_columns(folder_path, csv_file_name)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function reads a csv and changes its column names\n",
    "    to lowecase, removes spaces and replaces them with underscores\n",
    "    and removes the pound sign from the column names\n",
    "\n",
    "    This function assumes the original csv file has two headers!!!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data is saved\n",
    "    csv_file_name : str\n",
    "        Name of the csv file to be read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        final_df : pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(Path(folder_path,csv_file_name), sep=\",\", low_memory=False, encoding='cp1252')\n",
    "\n",
    "    # Data cleaning\n",
    "    sample_df_col = df.dropna(thresh=1 ,axis=1).dropna(thresh=1 ,axis=0)\n",
    "    sample_df_col.columns = [item.lower() for item in sample_df_col.columns]\n",
    "    sample_df_no_footer = sample_df_col.dropna(thresh=3 ,axis=0)\n",
    "    \n",
    "    # Remove Unnamed cols\n",
    "    cols = sample_df_no_footer.columns\n",
    "    cleaned_cols = [re.sub(r'unnamed: \\d*', \"fuel consumption\", item) if \"unnamed\" in item else item for item in cols]\n",
    "\n",
    "\n",
    "    # Clean row 1 on df\n",
    "    str_item_cols = [str(item) for item in sample_df_no_footer.iloc[0:1,].values[0]]\n",
    "    str_non_nan = [\"\" if item=='nan' else item for item in str_item_cols]\n",
    "\n",
    "    # Form new columns\n",
    "    new_cols = []\n",
    "    for itema,itemb in zip(cleaned_cols, str_non_nan):\n",
    "        new_cols.append(f'{itema}_{itemb}'.lower().replace(\"*\",\"\").replace(\" \",\"\").replace(r'#=highoutputengine',\"\"))\n",
    "\n",
    "    # Reset column names\n",
    "    final_df = sample_df_no_footer.iloc[1:, ].copy()\n",
    "    final_df.columns = new_cols\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5abcd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.267625Z",
     "iopub.status.busy": "2023-04-18T23:41:09.267467Z",
     "iopub.status.idle": "2023-04-18T23:41:09.271611Z",
     "shell.execute_reply": "2023-04-18T23:41:09.271246Z"
    },
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.008247,
     "end_time": "2023-04-18T23:41:09.272786",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.264539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_clean_csv_file(folder_path, csv_file_name) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function reads a csv file and performs data cleaning\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the folder where the data is saved\n",
    "    csv_file_name : str\n",
    "        Name of the csv file to be read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_df : pd.DataFrame\n",
    "        Dataframe containing the cleaned data\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    final_df = rename_fuel_data_columns(folder_path, csv_file_name)\n",
    "\n",
    "    # Additional data cleaning\n",
    "    final_df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Turn make, model.1_, vehicleclass_ into lowercase\n",
    "    final_df['make_'] = final_df['make_'].str.lower().str.strip()\n",
    "    final_df['model.1_'] = final_df['model.1_'].str.lower()\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].str.lower()\n",
    "\n",
    "    # Character cleaning for vehicleclass_: replace \":\" with \"-\"\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].str.replace(\":\",\" -\")\n",
    "\n",
    "    # Turn make, model.1_, vehicleclass_ into categorical variables\n",
    "    final_df['make_'] = final_df['make_'].astype('category')\n",
    "    final_df['model.1_'] = final_df['model.1_'].astype('category')\n",
    "    final_df['vehicleclass_'] = final_df['vehicleclass_'].astype('category')\n",
    "\n",
    "    # Mappings\n",
    "    final_df = final_df.join(final_df['transmission_'].str.split(r'(\\d+)', \\\n",
    "        expand=True).drop(columns=[2]).rename(columns={\n",
    "                                                        0:\"transmission_type\",\n",
    "                                                        1:\"number_of_gears\"}))\n",
    "    final_df['transmission_type'] = final_df['transmission_type'].map(transmission_dict)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3927ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.279081Z",
     "iopub.status.busy": "2023-04-18T23:41:09.278842Z",
     "iopub.status.idle": "2023-04-18T23:41:09.281978Z",
     "shell.execute_reply": "2023-04-18T23:41:09.281439Z"
    },
    "papermill": {
     "duration": 0.007822,
     "end_time": "2023-04-18T23:41:09.283170",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.275348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_model_key_words(s, dictionary):\n",
    "    \"\"\"\n",
    "    Add values from footnote\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        row of dataframe\n",
    "    dictionary : dict\n",
    "        one of the dictionaries defined globally.\n",
    "    \"\"\"\n",
    "\n",
    "    group = \"unspecified\"\n",
    "    for key in dictionary:\n",
    "        if key in s:\n",
    "            group = dictionary[key]\n",
    "            break\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46136cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.288922Z",
     "iopub.status.busy": "2023-04-18T23:41:09.288755Z",
     "iopub.status.idle": "2023-04-18T23:41:09.292260Z",
     "shell.execute_reply": "2023-04-18T23:41:09.291832Z"
    },
    "papermill": {
     "duration": 0.007701,
     "end_time": "2023-04-18T23:41:09.293423",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.285722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_stats_can_data(stats_can_url: str, folder_path:str, file_name : str) -> None:\n",
    "    \"\"\"\n",
    "    This function extracts data from StatsCan and saves it into a CSV file\n",
    "    Parameters:\n",
    "        stats_can_url (str): URL to StatsCan data\n",
    "        folder_path (str): Path to folder where data will be saved\n",
    "        file_name (str): Name of file where data will be saved\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    resp = urlopen(stats_can_url)\n",
    "    myzip = ZipFile(BytesIO(resp.read()))\n",
    "    extraction_file_name = [item for item in myzip.namelist() if \"MetaData\" not in item]\n",
    "    stats_can_csv = myzip.open(extraction_file_name[0])\n",
    "    stats_can_df = pd.read_csv(stats_can_csv)\n",
    "    stats_can_df.drop(columns=['DGUID',\n",
    "                             'UOM_ID',\n",
    "                             'SCALAR_ID',\n",
    "                             'VECTOR',\n",
    "                             'COORDINATE',\n",
    "                             'STATUS',\n",
    "                             'SYMBOL',\n",
    "                             'TERMINATED',\n",
    "                             'DECIMALS'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    stats_can_df.to_csv(Path(folder_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb38ba8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.299499Z",
     "iopub.status.busy": "2023-04-18T23:41:09.299285Z",
     "iopub.status.idle": "2023-04-18T23:41:09.304769Z",
     "shell.execute_reply": "2023-04-18T23:41:09.304411Z"
    },
    "papermill": {
     "duration": 0.009965,
     "end_time": "2023-04-18T23:41:09.306001",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.296036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_json_car_sales(json_filen_name, path) -> list():\n",
    "    \"\"\"\n",
    "    This function processes the JSON file containing car sales data and returns a dataframe\n",
    "    Parameters:\n",
    "        json_file_name (str): Name of JSON file\n",
    "        path (str): Path to folder where JSON file is located\n",
    "    Returns:\n",
    "        df_expanded_long (pd.DataFrame): Dataframe containing car sales data in long format\n",
    "        df_expanded_wide (pd.DataFrame): Dataframe containing car sales data in wide format\n",
    "\n",
    "    \"\"\"\n",
    "    json_df = pd.read_json(Path(path,json_filen_name)).set_index(\"model\")\n",
    "    json_df.dropna(how=\"all\", inplace=True)\n",
    "    \n",
    "    # Wide format\n",
    "    wide_df = pd.read_json(Path(path,json_filen_name))\n",
    "    df_expanded_wide = wide_df.join(wide_df.reset_index()['model'].str.split(' ', 1, expand=True).rename(columns={0:'make', 1:'model_'})).drop(columns=[\"model\"])\n",
    "    df_expanded_wide['year'] = json_filen_name.split(\"_\")[0]\n",
    "\n",
    "    # long format\n",
    "    long_format_df = pd.DataFrame(json_df.T.unstack()).reset_index().rename(columns={\"level_1\":\"month\",0:\"number_units_sold\"})\n",
    "    df_expanded_long = long_format_df.join(long_format_df.reset_index()['model'].str.split(' ', 1, expand=True).rename(columns={0:'make', 1:'model_'})).drop(columns=[\"model\"])\n",
    "    df_expanded_long['year'] = json_filen_name.split(\"_\")[0]\n",
    "    df_expanded_long['month']  = df_expanded_long['month'].map(month_dic) \n",
    "\n",
    "    # Remove ',' from number_units_sold\n",
    "    df_expanded_long['number_units_sold'] = df_expanded_long['number_units_sold'].str.replace(\",\",\"\")\n",
    "\n",
    "    # Transform month and number_units_sold to int \n",
    "    df_expanded_long['month'] = df_expanded_long['month'].astype('int')\n",
    "    df_expanded_long['number_units_sold'] = df_expanded_long['number_units_sold'].astype('int')\n",
    "\n",
    "    # Combine 'month' and 'year' into 'date' column and convert to datetime in format YYYY-MM \n",
    "    df_expanded_long['date'] = df_expanded_long['year'].astype(str) + \"-\" + df_expanded_long['month'].astype(str)\n",
    "    # Convert 'date' to datetime\n",
    "    df_expanded_long['date'] = pd.to_datetime(df_expanded_long['date'], format='%Y-%m')\n",
    "    # Drop 'month' and 'year' columns\n",
    "    df_expanded_long.drop(columns=['month','year'], inplace=True)\n",
    "\n",
    "    return df_expanded_long, df_expanded_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0c9be",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.00247,
     "end_time": "2023-04-18T23:41:09.310926",
     "exception": false,
     "start_time": "2023-04-18T23:41:09.308456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df24487",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd269b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T23:41:09.316826Z",
     "iopub.status.busy": "2023-04-18T23:41:09.316610Z",
     "iopub.status.idle": "2023-04-18T23:41:23.850647Z",
     "shell.execute_reply": "2023-04-18T23:41:23.849848Z"
    },
    "papermill": {
     "duration": 14.540916,
     "end_time": "2023-04-18T23:41:23.854303",
     "exception": true,
     "start_time": "2023-04-18T23:41:09.313387",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m     extract_stats_can_data(stats_can_dict[keys], clean_data_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Extract car sales data\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m long_format_2021_sep,df_2021 \u001b[38;5;241m=\u001b[39m  \u001b[43mprocess_json_car_sales\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2021_canada_vehicle_sales.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m long_format_2020_sep,df_2020 \u001b[38;5;241m=\u001b[39m  process_json_car_sales(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020_canada_vehicle_sales.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_data_path)\n\u001b[1;32m     89\u001b[0m long_format_2019_sep,df_2019 \u001b[38;5;241m=\u001b[39m  process_json_car_sales(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2019_canada_vehicle_sales.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_data_path)\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mprocess_json_car_sales\u001b[0;34m(json_filen_name, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_json_car_sales\u001b[39m(json_filen_name, path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    This function processes the JSON file containing car sales data and returns a dataframe\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     json_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mjson_filen_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     json_df\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Wide format\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/util/_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/io/json/_json.py:614\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/io/json/_json.py:748\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 748\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/io/json/_json.py:770\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 770\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/io/json/_json.py:885\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlenv/lib/python3.10/site-packages/pandas/io/json/_json.py:1140\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1140\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     )\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1143\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1146\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Set up relative paths\n",
    "    \n",
    "    # Variable initialization\n",
    "    raw_data_path = os.path.abspath(os.path.join(os.getcwd(), 'data', 'raw'))\n",
    "    clean_data_path = os.path.abspath(os.path.join(os.getcwd(), 'data', 'processed'))\n",
    "    \n",
    "    # Master dataframe initialization\n",
    "    fuel_based_df = []\n",
    "\n",
    "    # Fuel consumption metadata extraction urls\n",
    "    data_entries_english = fuel_consumption_metadata_extraction()\n",
    "    \n",
    "    # Iterate over entries\n",
    "    for item in data_entries_english.iterrows():\n",
    "        name, url = item[1][\"name\"], item[1][\"url\"]\n",
    "        \n",
    "        if \"Original\" in name:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Form file name\n",
    "        file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "        # Extract raw data\n",
    "        item_based_url  = extract_raw_data(url)\n",
    "\n",
    "        # Save raw data into a csv file\n",
    "        save_raw_data(raw_data_path,item_based_url)\n",
    "        \n",
    "        # Read and clean csv file\n",
    "        final_df = read_and_clean_csv_file(raw_data_path, name.replace(\" \",\"_\")+\".csv\")\n",
    "\n",
    "        # Populate dataframe with information from the footnotes\n",
    "        if \"hybrid\" in name:\n",
    "            # Strip numbers from file_name\n",
    "            name = re.sub(r'\\d+', '', name)\n",
    "            # Strip parenthesis and - from name\n",
    "            name = name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"\")\n",
    "            # Form file name\n",
    "            file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "            final_df.rename(columns={'fuel.1_type2': 'fuel_type2',\n",
    "                          'consumption.1_city(l/100km)': 'fuelconsumption_city(l/100km)',\n",
    "                        }, inplace=True)\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type2'].map(fuel_dict)\n",
    "            final_df['hybrid_fuels'] = final_df['fuel_type1'].map(hybrid_fuel_dict)\n",
    "            \n",
    "            final_df['id'] = range(1, len(final_df) + 1)\n",
    "            final_df['vehicle_type'] = \"hybrid\"\n",
    "            final_df.to_csv(Path(clean_data_path,file_name), index=False)\n",
    "        elif \"electric\" in name and \"hybrid\" not in name: \n",
    "            # Strip numbers from file_name\n",
    "            name = re.sub(r'\\d+', '', name)\n",
    "            # Strip parenthesis and - from name\n",
    "            name = name.replace(\"(\",\"\").replace(\")\",\"\").replace(\"-\",\"\")\n",
    "            # Form file name\n",
    "            file_name = f'{name.replace(\" \",\"_\")}.csv'\n",
    "\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type'].map(fuel_dict)\n",
    "            final_df['id'] = range(1, len(final_df) + 1)\n",
    "            final_df['vehicle_type'] = \"electric\"\n",
    "            final_df.to_csv(Path(clean_data_path,file_name), index=False)\n",
    "        else:\n",
    "            final_df['mapped_fuel_type'] = final_df['fuel_type'].map(fuel_dict)\n",
    "            final_df[\"type_of_wheel_drive\"] = final_df['model.1_'].apply(lambda x: convert_model_key_words(x, model_dict)) \n",
    "            fuel_based_df.append(final_df)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    fuel_based_df = pd.concat(fuel_based_df)\n",
    "\n",
    "    # add an id column where each row is a unique id (1, 2, 3, 4, ...)\n",
    "    fuel_based_df['id'] = range(1, len(fuel_based_df) + 1)\n",
    "\n",
    "    # Add a column called vehicle_type\n",
    "    fuel_based_df['vehicle_type'] = \"fuel-only\"\n",
    "    \n",
    "\n",
    "    # Save dataframes\n",
    "    fuel_based_df.to_csv(Path(clean_data_path,\"1995_today_vehicle_fuel_consumption.csv\"), index=False)\n",
    "    \n",
    "    # Extract StatsCan data\n",
    "    for keys in stats_can_dict:\n",
    "        extract_stats_can_data(stats_can_dict[keys], clean_data_path, f'{keys}.csv')\n",
    "\n",
    "    # Extract car sales data\n",
    "    long_format_2021_sep,df_2021 =  process_json_car_sales(\"2021_canada_vehicle_sales.json\", raw_data_path)\n",
    "    long_format_2020_sep,df_2020 =  process_json_car_sales(\"2020_canada_vehicle_sales.json\", raw_data_path)\n",
    "    long_format_2019_sep,df_2019 =  process_json_car_sales(\"2019_canada_vehicle_sales.json\", raw_data_path)\n",
    "\n",
    "    # Concatenate car sales data \n",
    "    long_format_car_sales = pd.concat([long_format_2019_sep, long_format_2020_sep, long_format_2021_sep])\n",
    "    wide_format_car_sales = pd.concat([df_2019, df_2020, df_2021])\n",
    "\n",
    "    # Save car sales data\n",
    "    long_format_car_sales.to_csv(Path(clean_data_path,\"long_format_car_sales.csv\"), index=False)\n",
    "    wide_format_car_sales.to_csv(Path(clean_data_path,\"wide_format_car_sales.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "papermill": {
   "duration": 16.326642,
   "end_time": "2023-04-18T23:41:24.188995",
   "exception": true,
   "input_path": "/var/folders/2t/nqb9hcfs07n91h4v5p34slp00000gn/T/tmp2gttyum7.ipynb",
   "output_path": "/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb",
   "parameters": {
    "product": {
     "nb": "/Users/macpro/Documents/GitHub/fuel-electric-hybrid-vehicle-ml/notebooks/data_extraction.ipynb"
    }
   },
   "start_time": "2023-04-18T23:41:07.862353"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}